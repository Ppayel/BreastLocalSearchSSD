{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_PSO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxuXTEPnYP7fUILXi4yAiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ppayel/BreastLocalSearchSSD/blob/main/utils/LS_PSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XncF26gNZHK"
      },
      "outputs": [],
      "source": [
        "!pip install Py-FS==0.0.39\n",
        "!pip install ReliefF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        " \n",
        "from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
        "from Py_FS.wrapper.nature_inspired._transfer_functions import get_trans_function\n",
        "\n",
        "#LAHC Local Search #####################################################\n",
        "omega = 0.2  #used in the fitness function\n",
        "delta=0.2   #to set an upper limit for including a slightly worse particle in LAHC\n",
        "def mutate(agent, num_features):\n",
        "      percent=0.2\n",
        "      numChange=int(num_features*percent)\n",
        "      pos=np.random.randint(0,num_features-1,numChange) #choose random positions to be mutated\n",
        "      agent[pos]=1-agent[pos] #mutation\n",
        "      return agent\n",
        " \n",
        "def LAHC(particle, train_X, val_X, train_Y, val_Y, weight_acc, num_features):\n",
        "      _lambda = 15 #upper limit on number of iterations in LAHC\n",
        "      target_fitness = compute_fitness(particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc) #original fitness\n",
        "      for i in range(_lambda):\n",
        "            new_particle = mutate(particle, num_features) #first mutation\n",
        "            temp = compute_fitness(new_particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "            if temp < target_fitness:\n",
        "                particle = new_particle.copy() #updation\n",
        "                target_fitness = temp\n",
        "            elif (temp<=(1+delta)*target_fitness):\n",
        "                temp_particle = new_particle.copy()\n",
        "                for j in range(_lambda):\n",
        "                    temp_particle1 = mutate(temp_particle, num_features) #second mutation\n",
        "                    temp_fitness = compute_fitness(temp_particle1, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "                    if temp_fitness < target_fitness:\n",
        "                        target_fitness=temp_fitness\n",
        "                        particle=temp_particle1.copy() #updation\n",
        "                    break\n",
        "      return particle\n",
        " \n",
        " \n",
        "#Adaptive beta local search ########################################################\n",
        " \n",
        "def randomwalk(agent):\n",
        "    percent = 30\n",
        "    percent /= 100\n",
        "    neighbor = agent.copy()\n",
        "    size = np.shape(agent)[0]\n",
        "    upper = int(percent*size)\n",
        "    if upper <= 1:\n",
        "        upper = size\n",
        "    x = random.randint(1,upper)\n",
        "    pos = random.sample(range(0,size - 1),x)\n",
        "    for i in pos:\n",
        "        neighbor[i] = 1 - neighbor[i]\n",
        "    return neighbor\n",
        " \n",
        "def adaptiveBeta(agent, train_X, val_X, train_Y, val_Y, weight_acc):\n",
        "    bmin = 0.1 #parameter: (can be made 0.01)\n",
        "    bmax = 1\n",
        "    maxIter = 10 # parameter: (can be increased )\n",
        "    \n",
        "    agentFit = compute_fitness(agent, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "    for curr in range(maxIter):\n",
        "        neighbor = agent.copy()\n",
        "        size = np.shape(neighbor)[0]\n",
        "        neighbor = randomwalk(neighbor)\n",
        " \n",
        "        beta = bmin + (curr / maxIter)*(bmax - bmin)\n",
        "        for i in range(size):\n",
        "            random.seed( time.time() + i )\n",
        "            if random.random() <= beta:\n",
        "                neighbor[i] = agent[i]\n",
        "        neighFit = compute_fitness(neighbor, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "        if neighFit <= agentFit:\n",
        "            agent = neighbor.copy()\n",
        "            \n",
        "    return agent\n",
        "\n",
        "############################# PSO #############################\n",
        "def PSO(num_agents, max_iter, train_data, train_label, obj_function=compute_fitness, trans_func_shape='s', save_conv_graph=False):\n",
        "    \n",
        "    # Particle Swarm Optimizer\n",
        "    ############################### Parameters ####################################\n",
        "    #                                                                             #\n",
        "    #   num_agents: number of particles                                           #\n",
        "    #   max_iter: maximum number of generations                                   #\n",
        "    #   train_data: training samples of data                                      #\n",
        "    #   train_label: class labels for the training samples                        #                \n",
        "    #   obj_function: the function to maximize while doing feature selection      #\n",
        "    #   trans_function_shape: shape of the transfer function used                 #\n",
        "    #   save_conv_graph: boolean value for saving convergence graph               #\n",
        "    #                                                                             #\n",
        "    ###############################################################################\n",
        "    \n",
        "    short_name = 'PSO'\n",
        "    agent_name = 'Particle'\n",
        "    train_data, train_label = np.array(train_data), np.array(train_label)\n",
        "    num_features = train_data.shape[1]\n",
        "    trans_function = get_trans_function(trans_func_shape)\n",
        "    \n",
        "    # setting up the objectives\n",
        "    weight_acc = None\n",
        "    if(obj_function==compute_fitness):\n",
        "        weight_acc = float(input('Weight for the classification accuracy [0-1]: '))\n",
        "    obj = (obj_function, weight_acc)\n",
        "    compute_accuracy = (compute_fitness, 1) # compute_accuracy is just compute_fitness with accuracy weight as 1\n",
        "\n",
        "    # initialize particles and Leader (the agent with the max fitness)\n",
        "    particles = initialize(num_agents, num_features)\n",
        "    fitness = np.zeros(num_agents)\n",
        "    accuracy = np.zeros(num_agents)\n",
        "    Leader_agent = np.zeros((1, num_features))\n",
        "    Leader_fitness = float(\"-inf\")\n",
        "    Leader_accuracy = float(\"-inf\")\n",
        "\n",
        "    # initialize convergence curves\n",
        "    convergence_curve = {}\n",
        "    convergence_curve['fitness'] = np.zeros(max_iter)\n",
        "\n",
        "    # initialize data class\n",
        "    data = Data()\n",
        "    val_size = float(input('Enter the percentage of data wanted for valdiation [0, 100]: '))/100\n",
        "    data.train_X, data.val_X, data.train_Y, data.val_Y = train_test_split(train_data, train_label, stratify=train_label, test_size=val_size, random_state = 50)\n",
        "\n",
        "    # create a solution object\n",
        "    solution = Solution()\n",
        "    solution.num_agents = num_agents\n",
        "    solution.max_iter = max_iter\n",
        "    solution.num_features = num_features\n",
        "    solution.obj_function = obj_function\n",
        "\n",
        "    # rank initial particles\n",
        "    particles, fitness = sort_agents(particles, obj, data)\n",
        "\n",
        "    # start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # initialize global and local best particles\n",
        "    globalBestParticle = [0 for i in range(num_features)]\n",
        "    globalBestFitness = float(\"-inf\")\n",
        "    localBestParticle = [ [ 0 for i in range(num_features) ] for j in range(num_agents) ] \n",
        "    localBestFitness = [float(\"-inf\") for i in range(num_agents) ]\n",
        "    weight = 1.0 \n",
        "    velocity = [ [ 0.0 for i in range(num_features) ] for j in range(num_agents) ]\n",
        "    \n",
        "    for iter_no in range(max_iter):\n",
        "        print('\\n================================================================================')\n",
        "        print('                          Iteration - {}'.format(iter_no+1))\n",
        "        print('================================================================================\\n')\n",
        "        \n",
        "        #Add local search for all the particles\n",
        "        train_X, val_X, train_Y, val_Y = data.train_X, data.val_X, data.train_Y, data.val_Y\n",
        "        for particle in range(num_agents):\n",
        "           particles[particle] = LAHC(particles[particle], train_X, val_X, train_Y, val_Y, weight_acc, num_features)  # To activte LAHC local search\n",
        "           #particles[particle] = adaptiveBeta(particles[particle], train_X, val_X, train_Y, val_Y, weight_acc)       # To activte ABHC local search\n",
        "\n",
        "\n",
        "        # update weight\n",
        "        weight = 1.0 - (iter_no / max_iter)\n",
        "        \n",
        "        # update the velocity\n",
        "        for i in range(num_agents):\n",
        "            for j in range(num_features):\n",
        "                velocity[i][j] = (weight*velocity[i][j])\n",
        "                r1, r2 = np.random.random(2)\n",
        "                velocity[i][j] = velocity[i][j] + (r1 * (localBestParticle[i][j] - particles[i][j]))\n",
        "                velocity[i][j] = velocity[i][j] + (r2 * (globalBestParticle[j] - particles[i][j]))\n",
        "       \n",
        "        # updating position of particles\n",
        "        for i in range(num_agents):\n",
        "            for j in range(num_features):\n",
        "                trans_value = trans_function(velocity[i][j])\n",
        "                if (np.random.random() < trans_value): \n",
        "                    particles[i][j] = 1\n",
        "                else:\n",
        "                    particles[i][j] = 0\n",
        "                 \n",
        "        # updating fitness of particles\n",
        "        particles, fitness = sort_agents(particles, obj, data)\n",
        "        display(particles, fitness, agent_name)\n",
        "        \n",
        "        \n",
        "        # updating the global best and local best particles\n",
        "        for i in range(num_agents):\n",
        "            if fitness[i]>localBestFitness[i]:\n",
        "                localBestFitness[i]=fitness[i]\n",
        "                localBestParticle[i]=particles[i][:]\n",
        "\n",
        "            if fitness[i]>globalBestFitness:\n",
        "                globalBestFitness=fitness[i]\n",
        "                globalBestParticle=particles[i][:]\n",
        "\n",
        "        # update Leader (best agent)\n",
        "        if globalBestFitness > Leader_fitness:\n",
        "            Leader_agent = globalBestParticle.copy()\n",
        "            Leader_fitness = globalBestFitness.copy()\n",
        "\n",
        "        convergence_curve['fitness'][iter_no] = np.mean(fitness)\n",
        "\n",
        "    # compute final accuracy\n",
        "    Leader_agent, Leader_accuracy = sort_agents(Leader_agent, compute_accuracy, data)\n",
        "    particles, accuracy = sort_agents(particles, compute_accuracy, data)\n",
        "\n",
        "    print('\\n================================================================================')\n",
        "    print('                                    Final Result                                  ')\n",
        "    print('================================================================================\\n')\n",
        "    print('Leader ' + agent_name + ' Dimension : {}'.format(int(np.sum(Leader_agent))))\n",
        "    print('Leader ' + agent_name + ' Fitness : {}'.format(Leader_fitness))\n",
        "    print('Leader ' + agent_name + ' Classification Accuracy : {}'.format(Leader_accuracy))\n",
        "    print('\\n================================================================================\\n')\n",
        "\n",
        "    # stop timer\n",
        "    end_time = time.time()\n",
        "    exec_time = end_time - start_time\n",
        "\n",
        "    # plot convergence graph\n",
        "    fig, axes = Conv_plot(convergence_curve)\n",
        "    if(save_conv_graph):\n",
        "        plt.savefig('convergence_graph_'+ short_name + '.jpg')\n",
        "    plt.show()\n",
        "\n",
        "    # update attributes of solution\n",
        "    solution.best_agent = Leader_agent\n",
        "    solution.best_fitness = Leader_fitness\n",
        "    solution.best_accuracy = Leader_accuracy\n",
        "    solution.convergence_curve = convergence_curve\n",
        "    solution.final_particles = particles\n",
        "    solution.final_fitness = fitness\n",
        "    solution.final_accuracy = accuracy\n",
        "    solution.execution_time = exec_time\n",
        "\n",
        "    return solution"
      ],
      "metadata": {
        "id": "841D1Cg-NnSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}