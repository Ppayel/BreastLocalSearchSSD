{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_HS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJKF61jr1j3lPuZtVDvm/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ppayel/BreastLocalSearchSSD/blob/main/utils/LS_HS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2H1GZ43QbeJ"
      },
      "outputs": [],
      "source": [
        "!pip install Py-FS==0.0.39\n",
        "!pip install ReliefF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
        "from Py_FS.wrapper.nature_inspired._transfer_functions import get_trans_function\n",
        "\n",
        "#LAHC Local Search #####################################################\n",
        "omega = 0.2  #used in the fitness function\n",
        "delta=0.2   #to set an upper limit for including a slightly worse particle in LAHC\n",
        "def mutate(agent, num_features):\n",
        "      percent=0.2\n",
        "      numChange=int(num_features*percent)\n",
        "      pos=np.random.randint(0,num_features-1,numChange) #choose random positions to be mutated\n",
        "      agent[pos]=1-agent[pos] #mutation\n",
        "      return agent\n",
        " \n",
        "def LAHC(particle, train_X, val_X, train_Y, val_Y, weight_acc, num_features):\n",
        "      _lambda = 15 #upper limit on number of iterations in LAHC\n",
        "      target_fitness = compute_fitness(particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc) #original fitness\n",
        "      for i in range(_lambda):\n",
        "            new_particle = mutate(particle, num_features) #first mutation\n",
        "            temp = compute_fitness(new_particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "            if temp < target_fitness:\n",
        "                particle = new_particle.copy() #updation\n",
        "                target_fitness = temp\n",
        "            elif (temp<=(1+delta)*target_fitness):\n",
        "                temp_particle = new_particle.copy()\n",
        "                for j in range(_lambda):\n",
        "                    temp_particle1 = mutate(temp_particle, num_features) #second mutation\n",
        "                    temp_fitness = compute_fitness(temp_particle1, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "                    if temp_fitness < target_fitness:\n",
        "                        target_fitness=temp_fitness\n",
        "                        particle=temp_particle1.copy() #updation\n",
        "                    break\n",
        "      return particle\n",
        " \n",
        " \n",
        "#Adaptive beta local search ########################################################\n",
        " \n",
        "def randomwalk(agent):\n",
        "    percent = 30\n",
        "    percent /= 100\n",
        "    neighbor = agent.copy()\n",
        "    size = np.shape(agent)[0]\n",
        "    upper = int(percent*size)\n",
        "    if upper <= 1:\n",
        "        upper = size\n",
        "    x = random.randint(1,upper)\n",
        "    pos = random.sample(range(0,size - 1),x)\n",
        "    for i in pos:\n",
        "        neighbor[i] = 1 - neighbor[i]\n",
        "    return neighbor\n",
        " \n",
        "def adaptiveBeta(agent, train_X, val_X, train_Y, val_Y, weight_acc):\n",
        "    bmin = 0.1 #parameter: (can be made 0.01)\n",
        "    bmax = 1\n",
        "    maxIter = 10 # parameter: (can be increased )\n",
        "    \n",
        "    agentFit = compute_fitness(agent, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "    for curr in range(maxIter):\n",
        "        neighbor = agent.copy()\n",
        "        size = np.shape(neighbor)[0]\n",
        "        neighbor = randomwalk(neighbor)\n",
        " \n",
        "        beta = bmin + (curr / maxIter)*(bmax - bmin)\n",
        "        for i in range(size):\n",
        "            random.seed( time.time() + i )\n",
        "            if random.random() <= beta:\n",
        "                neighbor[i] = agent[i]\n",
        "        neighFit = compute_fitness(neighbor, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "        if neighFit <= agentFit:\n",
        "            agent = neighbor.copy()\n",
        "            \n",
        "    return agent\n",
        "\n",
        "############################## HS  ##############################\n",
        "def HS(num_agents, max_iter, train_data, train_label, obj_function = compute_fitness, save_conv_graph = False):\n",
        "    \n",
        "    # Harmony Search Algorithm\n",
        "    ############################### Parameters ####################################\n",
        "    #                                                                             #\n",
        "    #   num_agents: number of harmonies                                           #\n",
        "    #   max_iter: maximum number of generations                                   #\n",
        "    #   train_data: training samples of data                                      #\n",
        "    #   train_label: class labels for the training samples                        #                \n",
        "    #   obj_function: the function to maximize while doing feature selection      #\n",
        "    #   trans_function_shape: shape of the transfer function used                 #\n",
        "    #   save_conv_graph: boolean value for saving convergence graph               #\n",
        "    #                                                                             #\n",
        "    ###############################################################################\n",
        "\n",
        "    # <STEPS OF HARMOMY SEARCH ALGORITH>\n",
        "    # Step 1. Initialize a Harmony Memory (HM).\n",
        "    # Step 2. Improvise a new harmony from HM.\n",
        "    # Step 3. If the new harmony is better than minimum harmony in HM, include the new harmony in HM, and exclude the minimum harmony from HM.\n",
        "    # Step 4. If stopping criteria are not satisfied, go to Step 2.\n",
        "\n",
        "    short_name = 'HS'\n",
        "    agent_name = 'Harmony'\n",
        "    train_data, train_label = np.array(train_data), np.array(train_label)\n",
        "    num_features = train_data.shape[1]\n",
        "\n",
        "    # setting up the objectives\n",
        "    weight_acc = None\n",
        "    if(obj_function==compute_fitness):\n",
        "        weight_acc = float(input('Weight for the classification accuracy [0-1]: '))\n",
        "    obj = (obj_function, weight_acc)\n",
        "    compute_accuracy = (compute_fitness, 1) # compute_accuracy is just compute_fitness with accuracy weight as 1\n",
        "\n",
        "    # intialize the harmonies and Leader (the agent with the max fitness)\n",
        "    harmonyMemory = initialize(num_agents, num_features)\n",
        "    fitness = np.zeros(num_agents)\n",
        "    accuracy = np.zeros(num_agents)\n",
        "    Leader_agent = np.zeros((1, num_features))\n",
        "    Leader_fitness = float(\"-inf\")\n",
        "    Leader_accuracy = float(\"-inf\")\n",
        "    HMCR = 0.90     # Harmony Memory Consideration Rate\n",
        "\n",
        "    # initialize convergence curves\n",
        "    convergence_curve = {}\n",
        "    convergence_curve['fitness'] = np.zeros(max_iter)\n",
        "\n",
        "    # initialize data class\n",
        "    data = Data()\n",
        "    val_size = float(input('Enter the percentage of data wanted for valdiation [0, 100]: '))/100\n",
        "    data.train_X, data.val_X, data.train_Y, data.val_Y = train_test_split(train_data, train_label, stratify=train_label, test_size=val_size)\n",
        "\n",
        "    # create a solution object\n",
        "    solution = Solution()\n",
        "    solution.num_agents = num_agents\n",
        "    solution.max_iter = max_iter\n",
        "    solution.num_features = num_features\n",
        "    solution.obj_function = obj_function\n",
        "\n",
        "    # start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # calculate initial fitess and sort the harmony memory and rank them\n",
        "    harmonyMemory, fitness = sort_agents(harmonyMemory, obj, data)\n",
        "\n",
        "    # create new harmonies in each iteration\n",
        "    for iter_no in range(max_iter):\n",
        "        print('\\n================================================================================')\n",
        "        print('                          Iteration - {}'.format(iter_no + 1))\n",
        "        print('================================================================================\\n')\n",
        "        \n",
        "        #Add local search for all the particles\n",
        "        train_X, val_X, train_Y, val_Y = data.train_X, data.val_X, data.train_Y, data.val_Y\n",
        "        for particle in range(num_agents):\n",
        "           #harmonyMemory[particle] = LAHC(harmonyMemory[particle], train_X, val_X, train_Y, val_Y, weight_acc, num_features)  # To activte LAHC local search\n",
        "           harmonyMemory[particle] = adaptiveBeta(harmonyMemory[particle], train_X, val_X, train_Y, val_Y, weight_acc)         # To activte ABHC local search\n",
        "        \n",
        "        \n",
        "        HMCR_randValue = np.random.rand()\n",
        "        newHarmony = np.zeros([1, num_features])\n",
        "\n",
        "        # print(HMCR)\n",
        "        # print(HMCR_randValue)\n",
        "\n",
        "        if HMCR_randValue <= HMCR:\n",
        "            for featureNum in range(num_features):\n",
        "                selectedAgent = random.randint(0, num_agents - 1)\n",
        "                newHarmony[0, featureNum] = harmonyMemory[selectedAgent, featureNum]\n",
        "\n",
        "        else:\n",
        "            for featureNum in range(num_features):\n",
        "                newHarmony[0, featureNum] = random.randint(0, 1)\n",
        "\n",
        "        fitnessHarmony = obj_function(newHarmony, data.train_X, data.val_X, data.train_Y, data.val_Y)\n",
        "\n",
        "        if fitness[num_agents-1] < fitnessHarmony:\n",
        "            harmonyMemory[num_agents-1, :] = newHarmony\n",
        "            fitness[num_agents-1] = fitnessHarmony\n",
        "\n",
        "        # sort harmony memory\n",
        "        harmonyMemory, fitness = sort_agents(harmonyMemory, obj, data)\n",
        "        \n",
        "        if fitness[0] > Leader_fitness:\n",
        "            Leader_agent = harmonyMemory[0].copy()\n",
        "            Leader_fitness = fitness[0].copy()\n",
        "\n",
        "        # update \n",
        "        convergence_curve['fitness'][iter_no] = np.mean(fitness)\n",
        "        display(harmonyMemory, fitness, agent_name)\n",
        "    \n",
        "    # compute final accuracy\n",
        "    Leader_agent, Leader_accuracy = sort_agents(Leader_agent, compute_accuracy, data)\n",
        "    harmonyMemory, accuracy = sort_agents(harmonyMemory, compute_accuracy, data)\n",
        "\n",
        "    print('\\n================================================================================')\n",
        "    print('                                    Final Result                                  ')\n",
        "    print('================================================================================\\n')\n",
        "    print('Leader ' + agent_name + ' Dimension : {}'.format(int(np.sum(Leader_agent))))\n",
        "    print('Leader ' + agent_name + ' Fitness : {}'.format(Leader_fitness))\n",
        "    print('Leader ' + agent_name + ' Classification Accuracy : {}'.format(Leader_accuracy))\n",
        "    print('\\n================================================================================\\n')\n",
        "\n",
        "    # leader agent and leader fitneess\n",
        "    Leader_fitness = fitness[0]\n",
        "    Leader_agent = harmonyMemory[0].copy()\n",
        "\n",
        "    # stop timer\n",
        "    end_time = time.time()\n",
        "    exec_time = end_time - start_time\n",
        "\n",
        "    # plot convergence graph\n",
        "    fig, axes = Conv_plot(convergence_curve)\n",
        "    if(save_conv_graph):\n",
        "        plt.savefig('convergence_graph_'+ short_name + '.jpg')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    solution.best_agent = Leader_agent\n",
        "    solution.best_fitness = Leader_fitness\n",
        "    solution.best_accuracy = Leader_accuracy\n",
        "    solution.convergence_curve = convergence_curve\n",
        "    solution.final_population = harmonyMemory\n",
        "    solution.final_fitness = fitness\n",
        "    solution.final_accuracy = accuracy\n",
        "    solution.execution_time = exec_time\n",
        "\n",
        "\n",
        "    return solution"
      ],
      "metadata": {
        "id": "hC6E4vDPQnVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}