{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_EO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPMfjgb/d2+/S6d8LcpHef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ppayel/BreastLocalSearchSSD/blob/main/utils/LS_EO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az-2ofnbQ14r"
      },
      "outputs": [],
      "source": [
        "!pip install Py-FS==0.0.39\n",
        "!pip install ReliefF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
        "from Py_FS.wrapper.nature_inspired._transfer_functions import get_trans_function\n",
        "\n",
        "#LAHC Local Search #####################################################\n",
        "omega = 0.2  #used in the fitness function\n",
        "delta=0.2   #to set an upper limit for including a slightly worse particle in LAHC\n",
        "def mutate(agent, num_features):\n",
        "      percent=0.2\n",
        "      numChange=int(num_features*percent)\n",
        "      pos=np.random.randint(0,num_features-1,numChange) #choose random positions to be mutated\n",
        "      agent[pos]=1-agent[pos] #mutation\n",
        "      return agent\n",
        " \n",
        "def LAHC(particle, train_X, val_X, train_Y, val_Y, weight_acc, num_features):\n",
        "      _lambda = 15 #upper limit on number of iterations in LAHC\n",
        "      target_fitness = compute_fitness(particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc) #original fitness\n",
        "      for i in range(_lambda):\n",
        "            new_particle = mutate(particle, num_features) #first mutation\n",
        "            temp = compute_fitness(new_particle, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "            if temp < target_fitness:\n",
        "                particle = new_particle.copy() #updation\n",
        "                target_fitness = temp\n",
        "            elif (temp<=(1+delta)*target_fitness):\n",
        "                temp_particle = new_particle.copy()\n",
        "                for j in range(_lambda):\n",
        "                    temp_particle1 = mutate(temp_particle, num_features) #second mutation\n",
        "                    temp_fitness = compute_fitness(temp_particle1, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "                    if temp_fitness < target_fitness:\n",
        "                        target_fitness=temp_fitness\n",
        "                        particle=temp_particle1.copy() #updation\n",
        "                    break\n",
        "      return particle\n",
        " \n",
        " \n",
        "#Adaptive beta local search ########################################################\n",
        " \n",
        "def randomwalk(agent):\n",
        "    percent = 30\n",
        "    percent /= 100\n",
        "    neighbor = agent.copy()\n",
        "    size = np.shape(agent)[0]\n",
        "    upper = int(percent*size)\n",
        "    if upper <= 1:\n",
        "        upper = size\n",
        "    x = random.randint(1,upper)\n",
        "    pos = random.sample(range(0,size - 1),x)\n",
        "    for i in pos:\n",
        "        neighbor[i] = 1 - neighbor[i]\n",
        "    return neighbor\n",
        " \n",
        "def adaptiveBeta(agent, train_X, val_X, train_Y, val_Y, weight_acc):\n",
        "    bmin = 0.1 #parameter: (can be made 0.01)\n",
        "    bmax = 1\n",
        "    maxIter = 10 # parameter: (can be increased )\n",
        "    \n",
        "    agentFit = compute_fitness(agent, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "    for curr in range(maxIter):\n",
        "        neighbor = agent.copy()\n",
        "        size = np.shape(neighbor)[0]\n",
        "        neighbor = randomwalk(neighbor)\n",
        " \n",
        "        beta = bmin + (curr / maxIter)*(bmax - bmin)\n",
        "        for i in range(size):\n",
        "            random.seed( time.time() + i )\n",
        "            if random.random() <= beta:\n",
        "                neighbor[i] = agent[i]\n",
        "        neighFit = compute_fitness(neighbor, train_X, val_X, train_Y, val_Y, weight_acc=weight_acc)\n",
        "        if neighFit <= agentFit:\n",
        "            agent = neighbor.copy()\n",
        "            \n",
        "    return agent\n",
        "\n",
        "######################### EO ####################################\n",
        "def EO(num_agents, max_iter, train_data, train_label, obj_function=compute_fitness, trans_func_shape='s', save_conv_graph=False):\n",
        "    \n",
        "    # Equilibrium Optimizer\n",
        "    ############################### Parameters ####################################\n",
        "    #                                                                             #\n",
        "    #   num_agents: number of particles                                           #\n",
        "    #   max_iter: maximum number of generations                                   #\n",
        "    #   train_data: training samples of data                                      #\n",
        "    #   train_label: class labels for the training samples                        #                \n",
        "    #   obj_function: the function to maximize while doing feature selection      #\n",
        "    #   trans_function_shape: shape of the transfer function used                 #\n",
        "    #   save_conv_graph: boolean value for saving convergence graph               #\n",
        "    #                                                                             #\n",
        "    ###############################################################################\n",
        "    \n",
        "    short_name = 'EO'\n",
        "    agent_name = 'Particle'\n",
        "    train_data, train_label = np.array(train_data), np.array(train_label)\n",
        "    num_features = train_data.shape[1]\n",
        "    trans_function = get_trans_function(trans_func_shape)\n",
        "\n",
        "    # setting up the objectives\n",
        "    weight_acc = None\n",
        "    if(obj_function==compute_fitness):\n",
        "        weight_acc = float(input('Weight for the classification accuracy [0-1]: '))\n",
        "    obj = (obj_function, weight_acc)\n",
        "    compute_accuracy = (compute_fitness, 1) # compute_accuracy is just compute_fitness with accuracy weight as 1\n",
        "\n",
        "    # initialize particles and Leader (the agent with the max fitness)\n",
        "    particles = initialize(num_agents, num_features)\n",
        "    fitness = np.zeros(num_agents)\n",
        "    accuracy = np.zeros(num_agents)\n",
        "    Leader_agent = np.zeros((1, num_features))\n",
        "    Leader_fitness = float(\"-inf\")\n",
        "    Leader_accuracy = float(\"-inf\")\n",
        "    pool_size = 4\n",
        "    omega = 0.9                 \n",
        "    a2 = 1\n",
        "    a1 = 2\n",
        "    GP = 0.5\n",
        "\n",
        "    # initialize convergence curves\n",
        "    convergence_curve = {}\n",
        "    convergence_curve['fitness'] = np.zeros(max_iter)\n",
        "\n",
        "    # initialize data class\n",
        "    data = Data()\n",
        "    val_size = float(input('Enter the percentage of data wanted for valdiation [0, 100]: '))/100\n",
        "    data.train_X, data.val_X, data.train_Y, data.val_Y = train_test_split(train_data, train_label, stratify=train_label, test_size=val_size)\n",
        "\n",
        "    # create a solution object\n",
        "    solution = Solution()\n",
        "    solution.num_agents = num_agents\n",
        "    solution.max_iter = max_iter\n",
        "    solution.num_features = num_features\n",
        "    solution.obj_function = obj_function\n",
        "\n",
        "    # rank initial particles\n",
        "    particles, fitness = sort_agents(particles, obj, data)\n",
        "\n",
        "    # start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # pool initialization\n",
        "    eq_pool = np.zeros((pool_size+1, num_features))\n",
        "    eq_fitness = np.zeros(pool_size)\n",
        "    eq_fitness[:] = float(\"-inf\")\n",
        "\n",
        "    for iter_no in range(max_iter):\n",
        "        print('\\n================================================================================')\n",
        "        print('                          Iteration - {}'.format(iter_no+1))\n",
        "        print('================================================================================\\n')     \n",
        "\n",
        "        #Add local search for all the particles\n",
        "        train_X, val_X, train_Y, val_Y = data.train_X, data.val_X, data.train_Y, data.val_Y\n",
        "        for particle in range(num_agents):\n",
        "           particles[particle] = LAHC(particles[particle], train_X, val_X, train_Y, val_Y, weight_acc, num_features)   # To activte LAHC local search\n",
        "           #particles[particle] = adaptiveBeta(particles[particle], train_X, val_X, train_Y, val_Y, weight_acc)        # To activte ABHC local search\n",
        "\n",
        "\n",
        "        # replacements in the pool\n",
        "        for i in range(num_agents):\n",
        "            for j in range(pool_size):                 \n",
        "                if fitness[i] <= eq_fitness[j]:\n",
        "                    eq_fitness[j] = fitness[i].copy()\n",
        "                    eq_pool[j, :] = particles[i, :].copy()\n",
        "                    break\n",
        "        \n",
        "\n",
        "        best_particle = eq_pool[0,:]\n",
        "                \n",
        "        Cave = avg_concentration(eq_pool, pool_size, num_features)\n",
        "        eq_pool[pool_size] = Cave.copy()\n",
        "\n",
        "        t = (1 - (iter_no/max_iter)) ** (a2*iter_no/max_iter)\n",
        "        \n",
        "        for i in range(num_agents):\n",
        "            \n",
        "            # randomly choose one candidate from the equillibrium pool\n",
        "            inx = np.random.randint(0,pool_size)\n",
        "            Ceq = np.array(eq_pool[inx])\n",
        "\n",
        "            lambda_vec = np.zeros(np.shape(Ceq))\n",
        "            r_vec = np.zeros(np.shape(Ceq))\n",
        "            for j in range(num_features):\n",
        "                lambda_vec[j] = np.random.random()\n",
        "                r_vec[j] = np.random.random()\n",
        "\n",
        "            F_vec = np.zeros(np.shape(Ceq))\n",
        "            for j in range(num_features):\n",
        "                x = -1*lambda_vec[j]*t \n",
        "                x = np.exp(x) - 1\n",
        "                x = a1 * sign_func(r_vec[j] - 0.5) * x\n",
        "\n",
        "            r1, r2 = np.random.random(2)\n",
        "            if r2 < GP:\n",
        "                GCP = 0\n",
        "            else:\n",
        "                GCP = 0.5 * r1\n",
        "            G0 = np.zeros(np.shape(Ceq))\n",
        "            G = np.zeros(np.shape(Ceq))\n",
        "            for j in range(num_features):\n",
        "                G0[j] = GCP * (Ceq[j] - lambda_vec[j]*particles[i][j])\n",
        "                G[j] = G0[j]*F_vec[j]\n",
        "            \n",
        "            # use transfer function to map continuous->binary\n",
        "            for j in range(num_features):\n",
        "                temp = Ceq[j] + (particles[i][j] - Ceq[j])*F_vec[j] + G[j]*(1 - F_vec[j])/lambda_vec[j]                \n",
        "                temp = trans_function(temp)                \n",
        "                if temp>np.random.random():\n",
        "                    particles[i][j] = 1 - particles[i][j]\n",
        "                else:\n",
        "                    particles[i][j] = particles[i][j]          \n",
        "\n",
        "        # update final information\n",
        "        particles, fitness = sort_agents(particles, obj, data)\n",
        "        display(particles, fitness, agent_name)\n",
        "        \n",
        "        # update Leader (best agent)\n",
        "        if fitness[0] > Leader_fitness:\n",
        "            Leader_agent = particles[0].copy()\n",
        "            Leader_fitness = fitness[0].copy()\n",
        "\n",
        "        convergence_curve['fitness'][iter_no] = np.mean(fitness)\n",
        "\n",
        "    # compute final accuracy\n",
        "    Leader_agent, Leader_accuracy = sort_agents(Leader_agent, compute_accuracy, data)\n",
        "    particles, accuracy = sort_agents(particles, compute_accuracy, data)\n",
        "\n",
        "    print('\\n================================================================================')\n",
        "    print('                                    Final Result                                  ')\n",
        "    print('================================================================================\\n')\n",
        "    print('Leader ' + agent_name + ' Dimension : {}'.format(int(np.sum(Leader_agent))))\n",
        "    print('Leader ' + agent_name + ' Fitness : {}'.format(Leader_fitness))\n",
        "    print('Leader ' + agent_name + ' Classification Accuracy : {}'.format(Leader_accuracy))\n",
        "    print('\\n================================================================================\\n')\n",
        "\n",
        "    # stop timer\n",
        "    end_time = time.time()\n",
        "    exec_time = end_time - start_time\n",
        "\n",
        "    # plot convergence graph\n",
        "    fig, axes = Conv_plot(convergence_curve)\n",
        "    if(save_conv_graph):\n",
        "        plt.savefig('convergence_graph_'+ short_name + '.jpg')\n",
        "    plt.show()\n",
        "\n",
        "    # update attributes of solution\n",
        "    solution.best_agent = Leader_agent\n",
        "    solution.best_fitness = Leader_fitness\n",
        "    solution.best_accuracy = Leader_accuracy\n",
        "    solution.convergence_curve = convergence_curve\n",
        "    solution.final_population = particles\n",
        "    solution.final_fitness = fitness\n",
        "    solution.final_accuracy = accuracy\n",
        "    solution.execution_time = exec_time\n",
        "\n",
        "    return solution\n",
        "\n",
        "\n",
        "def avg_concentration(eq_pool, pool_size, dimension): \n",
        "    # function to compute average concentration of the equilibrium pool   \n",
        "    avg = np.sum(eq_pool[0:pool_size,:], axis=0)         \n",
        "    avg = avg/pool_size\n",
        "    return avg\n",
        "\n",
        "\n",
        "def sign_func(x): \n",
        "    # signum function\n",
        "    if x<0:\n",
        "        return -1\n",
        "    return 1"
      ],
      "metadata": {
        "id": "1SOmk3QxRBE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}